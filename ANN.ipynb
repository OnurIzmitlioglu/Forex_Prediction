{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define API key to be able to use the Alpha Vantage API.\n",
    "# Alpha Vantage API allows us to get any parity's intraday/daily/weekly currency exchange rates. \n",
    "api_key=\"4YOBCFLPOVPZVL3D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# To be able to import ForeignExchange, the command:\n",
    "#     pip install alpha_vantage\n",
    "# must be executed.\n",
    "from alpha_vantage.foreignexchange import ForeignExchange\n",
    "\n",
    "# Import other necessary libraries such as numpy, pandas ...\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# forex is set to be the instance of the ForeignExchange class.\n",
    "forex = ForeignExchange(key=api_key,output_format=\"pandas\")\n",
    "\n",
    "\n",
    "# ForeignExchange class has method named get_currency_exchange_daily that returns the daily dataset of given parity.\n",
    "data1, _ = forex.get_currency_exchange_daily(\"USD\",'EUR',\"pandas\")\n",
    "data2, _ = forex.get_currency_exchange_weekly(\"USD\", \"EUR\",\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, we create a DataFrame with the returned dataset.\n",
    "df2 = pd.DataFrame(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Our features on both SVM model and ANN model are determined to be\n",
    "# the moving averages of 5 days, 10 days, 20 days, 60 days, 120 days and \n",
    "# the closing rate of previous are held in feature columns. \n",
    "featurecolumns =[\"MA5\", \"MA10\", \"MA20\", \"MA60\",\"MA120\", \"Previous Day\"]\n",
    "featureframe = pd.DataFrame(data = None, columns = featurecolumns)\n",
    "\n",
    "# Moving averages are calculated by \n",
    "featureframe['MA5'] = df2.rolling(5).sum()[\"4. close\"]/5\n",
    "featureframe['MA10'] = df2.rolling(10).sum()[\"4. close\"]/10\n",
    "featureframe['MA20'] = df2.rolling(20).sum()[\"4. close\"]/20\n",
    "featureframe['MA60'] = df2.rolling(60).sum()[\"4. close\"]/60\n",
    "featureframe['MA120'] = df2.rolling(120).sum()[\"4. close\"]/120\n",
    "featureframe[\"Previous Day\"] = df2[\"4. close\"]\n",
    "\n",
    "# We shift the feature frame to be able to predict the next day's closing rate \n",
    "# by looking at the moving averages of the day before.\n",
    "featureframe = featureframe.shift(1)\n",
    "\n",
    "# After the shift operation, we construct the closing rate.\n",
    "featureframe[\"Closing Rate\"] = df2[\"4. close\"]\n",
    "\n",
    "# To calculate the moving average of x days, we need at least the data of first x days and to prevent errors,\n",
    "# we drop the data of last day.\n",
    "featureframe = featureframe.drop(featureframe.index[len(featureframe)-1])\n",
    "featureframe = featureframe.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we apply the ANN, we should split the data into test and train randomly.\n",
    "# The model is built as %30 training, %70 testing.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(featureframe[featurecolumns], featureframe[\"Closing Rate\"], test_size = 0.70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "# Initialize the Multiple Layer Regressor class instance.\n",
    "nn = MLPRegressor(hidden_layer_sizes=(6), max_iter=10000,early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the train data.\n",
    "trainFitted = nn.fit(Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction on the fitted train data on test data.\n",
    "prediction = trainFitted.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.760444953116708e-08"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the test error.\n",
    "counter = 0\n",
    "E_test = 0\n",
    "TestError= 0\n",
    "for x, y in np.nditer([prediction, ytest.values],[\"refs_ok\"]):\n",
    "    E_test = float(x) - float(y)\n",
    "    E_test **= 2\n",
    "    counter +=1\n",
    "E_test = E_test/counter\n",
    "print(\"The test error: {}\".format(E_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alphas are tested to evaluate the bias-variance tradeoff (regularization term)\n",
    "alphaList = np.array([1e-6, 1e-5,1e-4,1e-3,1e-2,1e-1])\n",
    "# Number of nodes in the hidden layer is another performance metric.\n",
    "hiddenLayerList = np.array([(7),(6),(5),(4),(3)])\n",
    "TotalEins= []\n",
    "TotalEvals= []\n",
    "TotalEval = 0\n",
    "# For each (# nodes in hiddenlayer, alpha value) tuple, evaluate the cross validation error.\n",
    "for j, Q in enumerate(alphaList):\n",
    "    for i, C in enumerate(hiddenLayerList):\n",
    "        for i in range(int(ytrain.size/10)):\n",
    "            validtestfeature = Xtrain[(i*10):(i+1)*10]\n",
    "            validtestlabel = ytrain[(i*10):(i+1)*10]\n",
    "            validtrainfeature = np.delete(Xtrain.values, np.s_[(i*10):(i+1)*10], 0)\n",
    "            validtrainlabel = np.delete(ytrain.values, np.s_[(i*10):(i+1)*10], 0)\n",
    "            prob = MLPRegressor(hidden_layer_sizes=C, max_iter=10000,early_stopping=True, alpha=Q)\n",
    "            m = prob.fit(validtrainfeature, validtrainlabel)\n",
    "            p_valtest = prob.predict(validtestfeature)\n",
    "            counter = 0\n",
    "            E_val = 0\n",
    "            for x, y in np.nditer([p_valtest, validtestlabel.values],[\"refs_ok\"]):\n",
    "                E_val  = float(x) - float(y)\n",
    "                E_val = E_val**2\n",
    "                counter +=1\n",
    "            E_val = E_val/counter\n",
    "            TotalEval += E_val\n",
    "        TotalEval=TotalEval/int(ytrain.size/10)\n",
    "        TotalEvals.append(TotalEval)\n",
    "        TotalEval = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "Q = 0.000001, C = 7 , Ecval = 2.40322817956161008434e-05\n",
      "Q = 0.000001, C = 6 , Ecval = 5.56414203843953085807e-05\n",
      "Q = 0.000001, C = 5 , Ecval = 1.35056554488677157651e-04\n",
      "Q = 0.000001, C = 4 , Ecval = 5.89320810196753005431e-05\n",
      "Q = 0.000001, C = 3 , Ecval = 1.97986599700566913602e-04\n",
      "Q = 0.000010, C = 7 , Ecval = 1.90949633505176666034e-04\n",
      "Q = 0.000010, C = 6 , Ecval = 9.34296632522283560743e-05\n",
      "Q = 0.000010, C = 5 , Ecval = 7.10006440068569074199e-05\n",
      "Q = 0.000010, C = 4 , Ecval = 6.56837440768224558024e-05\n",
      "Q = 0.000010, C = 3 , Ecval = 1.54187200681591237610e-04\n",
      "Q = 0.000100, C = 7 , Ecval = 5.33741739623353215810e-05\n",
      "Q = 0.000100, C = 6 , Ecval = 1.09275566719924962069e-04\n",
      "Q = 0.000100, C = 5 , Ecval = 7.57221370914993170383e-05\n",
      "Q = 0.000100, C = 4 , Ecval = 7.04177807868445077575e-05\n",
      "Q = 0.000100, C = 3 , Ecval = 7.63724729032888279088e-05\n",
      "|||THIS ONE BELOW:|||\n",
      "Q = 0.001000, C = 7 , Ecval = 2.13254008940999228408e-05\n",
      "Q = 0.001000, C = 6 , Ecval = 1.21551254811625198435e-04\n",
      "Q = 0.001000, C = 5 , Ecval = 9.40423215186890514624e-05\n",
      "Q = 0.001000, C = 4 , Ecval = 4.92385112699916669332e-05\n",
      "Q = 0.001000, C = 3 , Ecval = 6.11170693599764121729e-05\n",
      "Q = 0.010000, C = 7 , Ecval = 4.59598953751203312401e-05\n",
      "Q = 0.010000, C = 6 , Ecval = 9.47921747841958206799e-05\n",
      "Q = 0.010000, C = 5 , Ecval = 7.06129425307816066494e-05\n",
      "Q = 0.010000, C = 4 , Ecval = 1.76727155979878729512e-04\n",
      "Q = 0.010000, C = 3 , Ecval = 7.63025278761333373024e-05\n",
      "Q = 0.100000, C = 7 , Ecval = 2.56570258853077845984e-05\n",
      "Q = 0.100000, C = 6 , Ecval = 6.75499411992605915990e-05\n",
      "Q = 0.100000, C = 5 , Ecval = 7.61566954309727438743e-05\n",
      "Q = 0.100000, C = 4 , Ecval = 1.66627501628602617788e-04\n",
      "Q = 0.100000, C = 3 , Ecval = 1.94639091642247858381e-04\n"
     ]
    }
   ],
   "source": [
    "print(TotalEvals.index(min(TotalEvals)))\n",
    "counter = 0\n",
    "# Assign the best alpha value and the best hidden layer size by looking at the cross validation error of each.\n",
    "for j, Q in enumerate(alphaList):\n",
    "    for i, C in enumerate(hiddenLayerList):\n",
    "        if TotalEvals.index(min(TotalEvals)) == counter:\n",
    "            BestCs = C\n",
    "            BestQ = Q\n",
    "            print(\"|||THIS ONE BELOW:|||\")\n",
    "        print(\"Q = %lf, C = %s , Ecval = %.20e\" % (Q, C, TotalEvals[counter]))\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.49499330736349e-07"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, predict the rate by applying the best hidden layer node number and best alpha value.\n",
    "# Make a prediction on the real data of exchange rates.\n",
    "prob = MLPRegressor(hidden_layer_sizes=(BestCs), max_iter=10000,early_stopping=True, alpha=BestQ)\n",
    "m = prob.fit(Xtrain, ytrain)\n",
    "p_test = prob.predict(Xtest)\n",
    "counter = 0\n",
    "E_test = 0\n",
    "TestError= 0\n",
    "for x, y in np.nditer([p_test, ytest.values],[\"refs_ok\"]):\n",
    "    E_test  = float(x) - float(y)\n",
    "    E_test = E_test**2\n",
    "    counter +=1\n",
    "E_test = E_test/counter\n",
    "E_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "deneme = prob.predict(featureframe[featurecolumns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1dc96668>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the actual data, and predicted data alltogether.\n",
    "plotframe = featureframe[\"Closing Rate\"]\n",
    "plotframe = plotframe.to_frame()\n",
    "plotframe2 = pd.DataFrame(deneme,columns=[\"Predict\"])\n",
    "plotframe.plot(figsize=(10,5))\n",
    "plotframe2.plot(figsize=(10,5))\n",
    "plotframe2[\"Closing Rate\"] = plotframe.values\n",
    "plotframe2.plot(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006404995734038393"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find out the normalized mean square error.\n",
    "E_test/ytest.values.astype(\"float\").std()**2\n",
    "# Equal to normalized mean square error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Bool\n",
       "count    1397\n",
       "unique      2\n",
       "top     False\n",
       "freq      709"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closeT = (plotframe2[\"Closing Rate\"]-plotframe2.shift(1)[\"Closing Rate\"]).dropna().values\n",
    "predictT = (plotframe2[\"Predict\"]-plotframe2.shift(1)[\"Predict\"]).dropna().values\n",
    "closeT[closeT > 0] = 1\n",
    "closeT[closeT < 0] = -1\n",
    "predictT[predictT > 0] = 1\n",
    "predictT[predictT < 0] = -1\n",
    "\n",
    "trendFrame = pd.DataFrame(data = (predictT == closeT), columns = [\"Bool\"])\n",
    "trendFrame.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
