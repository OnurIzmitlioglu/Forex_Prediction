{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define API key to be able to use the Alpha Vantage API.\n",
    "# Alpha Vantage API allows us to get any parity's intraday/daily/weekly currency exchange rates. \n",
    "api_key=\"4YOBCFLPOVPZVL3D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# To be able to import ForeignExchange, the command:\n",
    "#     pip install alpha_vantage\n",
    "# must be executed.\n",
    "from alpha_vantage.foreignexchange import ForeignExchange\n",
    "\n",
    "# Import other necessary libraries such as numpy, pandas ...\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# cc is set to be the instance of the ForeignExchange class.\n",
    "cc = ForeignExchange(key=api_key,output_format=\"pandas\")\n",
    "\n",
    "\n",
    "# ForeignExchange class has method named get_currency_exchange_daily that returns the daily dataset of given parity.\n",
    "data1, _ = cc.get_currency_exchange_daily(\"USD\",'EUR',\"pandas\")\n",
    "data2, _ = cc.get_currency_exchange_weekly(\"USD\", \"EUR\",\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, we create a DataFrame with the returned dataset.\n",
    "df2 = pd.DataFrame(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Our features on both SVM model and ANN model are determined to be\n",
    "# the moving averages of 5 days, 10 days, 20 days, 60 days, 120 days and \n",
    "# the closing rate of previous are held in feature columns. \n",
    "featurecolumns =[\"MA5\", \"MA10\", \"MA20\", \"MA60\",\"MA120\", \"Previous Day\"]\n",
    "featureframe = pd.DataFrame(data = None, columns = featurecolumns)\n",
    "# Moving averages are calculated by \n",
    "featureframe['MA5'] = df2.rolling(5).sum()[\"4. close\"]/5\n",
    "featureframe['MA10'] = df2.rolling(10).sum()[\"4. close\"]/10\n",
    "featureframe['MA20'] = df2.rolling(20).sum()[\"4. close\"]/20\n",
    "featureframe['MA60'] = df2.rolling(60).sum()[\"4. close\"]/60\n",
    "featureframe['MA120'] = df2.rolling(120).sum()[\"4. close\"]/120\n",
    "featureframe[\"Previous Day\"] = df2[\"4. close\"]\n",
    "# We shift the feature frame to be able to predict the next day's closing rate by looking at the moving averages of the day before.\n",
    "featureframe = featureframe.shift(1)\n",
    "# After the shift operation, we construct the closing rate.\n",
    "featureframe[\"Closing Rate\"] = df2[\"4. close\"]\n",
    "\n",
    "# To calculate the moving average of x days, we need at least the data of first x days and to prevent errors,\n",
    "# we drop the data of last day.\n",
    "featureframe = featureframe.drop(featureframe.index[len(featureframe)-1])\n",
    "featureframe = featureframe.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we apply the ANN, we should split the data into test and train randomly.\n",
    "# The model is built as %10train %90test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(featureframe[featurecolumns], featureframe[\"Closing Rate\"], test_size = 0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "# Initialize the Multiple Layer Regressor class instance.\n",
    "nn = MLPRegressor(hidden_layer_sizes=(6), max_iter=10000,early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the train data.\n",
    "trainFitted = nn.fit(Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction on the fitted train data on test data.\n",
    "prediction = trainFitted.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.042637930724378e-08"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the test error.\n",
    "counter = 0\n",
    "E_test = 0\n",
    "TestError= 0\n",
    "for x, y in np.nditer([prediction, ytest.values],[\"refs_ok\"]):\n",
    "    E_test  = float(x) - float(y)\n",
    "    E_test = E_test**2\n",
    "    counter +=1\n",
    "E_test = E_test/counter\n",
    "E_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alphas are tested to evaluate the bias-variance tradeoff (regularization term)\n",
    "alphaList = np.array([1e-6, 1e-5,1e-4,1e-3,1e-2,1e-1])\n",
    "# Number of nodes in the hidden layer is another performance metric.\n",
    "hiddenLayerList = np.array([(7),(6),(5),(4),(3)])\n",
    "TotalEins= []\n",
    "TotalEvals= []\n",
    "TotalEval = 0\n",
    "# For each (# nodes in hiddenlayer, alpha value) tuple, evaluate the cross validation error.\n",
    "for j, Q in enumerate(alphaList):\n",
    "    for i, C in enumerate(hiddenLayerList):\n",
    "        for i in range(int(ytrain.size/10)):\n",
    "            validtestfeature = Xtrain[(i*10):(i+1)*10]\n",
    "            validtestlabel = ytrain[(i*10):(i+1)*10]\n",
    "            validtrainfeature = np.delete(Xtrain.values, np.s_[(i*10):(i+1)*10], 0)\n",
    "            validtrainlabel = np.delete(ytrain.values, np.s_[(i*10):(i+1)*10], 0)\n",
    "            prob = MLPRegressor(hidden_layer_sizes=C, max_iter=10000,early_stopping=True, alpha=Q)\n",
    "            m = prob.fit(validtrainfeature, validtrainlabel)\n",
    "            p_valtest = prob.predict(validtestfeature)\n",
    "            counter = 0\n",
    "            E_val = 0\n",
    "            for x, y in np.nditer([p_valtest, validtestlabel.values],[\"refs_ok\"]):\n",
    "                E_val  = float(x) - float(y)\n",
    "                E_val = E_val**2\n",
    "                counter +=1\n",
    "            E_val = E_val/counter\n",
    "            TotalEval += E_val\n",
    "        TotalEval=TotalEval/int(ytrain.size/10)\n",
    "        TotalEvals.append(TotalEval)\n",
    "        TotalEval = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "Q = 0.000001, C = 7 , Ecval = 1.86726082716026479686e-04\n",
      "Q = 0.000001, C = 6 , Ecval = 8.76516745094052166344e-05\n",
      "Q = 0.000001, C = 5 , Ecval = 4.92820490891937018217e-05\n",
      "Q = 0.000001, C = 4 , Ecval = 4.77618313789865341383e-05\n",
      "Q = 0.000001, C = 3 , Ecval = 1.93625904251402275458e-04\n",
      "Q = 0.000010, C = 7 , Ecval = 1.12651400422986708977e-04\n",
      "Q = 0.000010, C = 6 , Ecval = 5.21944708394919359529e-05\n",
      "Q = 0.000010, C = 5 , Ecval = 1.29382816122523147543e-04\n",
      "Q = 0.000010, C = 4 , Ecval = 3.61392633909546042228e-04\n",
      "Q = 0.000010, C = 3 , Ecval = 2.16774520292150626012e-04\n",
      "Q = 0.000100, C = 7 , Ecval = 7.51264443935591679077e-05\n",
      "Q = 0.000100, C = 6 , Ecval = 7.38742673859358526915e-05\n",
      "Q = 0.000100, C = 5 , Ecval = 5.41744782887182825494e-05\n",
      "Q = 0.000100, C = 4 , Ecval = 1.64723183619531771821e-04\n",
      "Q = 0.000100, C = 3 , Ecval = 5.21560578387110951749e-05\n",
      "Q = 0.001000, C = 7 , Ecval = 7.27761609642543587633e-05\n",
      "Q = 0.001000, C = 6 , Ecval = 1.54759569515152919277e-04\n",
      "Q = 0.001000, C = 5 , Ecval = 7.97476570972982388074e-05\n",
      "Q = 0.001000, C = 4 , Ecval = 1.77084824495971131187e-04\n",
      "Q = 0.001000, C = 3 , Ecval = 1.24682722335435345251e-04\n",
      "|||THIS ONE BELOW:|||\n",
      "Q = 0.010000, C = 7 , Ecval = 4.55922234988431372346e-05\n",
      "Q = 0.010000, C = 6 , Ecval = 1.20248926062837096216e-04\n",
      "Q = 0.010000, C = 5 , Ecval = 1.57922506962505433030e-04\n",
      "Q = 0.010000, C = 4 , Ecval = 5.16714158634447090143e-04\n",
      "Q = 0.010000, C = 3 , Ecval = 1.45886098266606297012e-04\n",
      "Q = 0.100000, C = 7 , Ecval = 1.35872353255552240792e-04\n",
      "Q = 0.100000, C = 6 , Ecval = 1.15235290760473373388e-04\n",
      "Q = 0.100000, C = 5 , Ecval = 1.04224689097484298547e-04\n",
      "Q = 0.100000, C = 4 , Ecval = 4.87443925156610800191e-05\n",
      "Q = 0.100000, C = 3 , Ecval = 7.15778625553202015172e-05\n"
     ]
    }
   ],
   "source": [
    "print(TotalEvals.index(min(TotalEvals)))\n",
    "counter = 0\n",
    "# Assign the best alpha value and the best hidden layer size by looking at the cross validation error of each.\n",
    "for j, Q in enumerate(alphaList):\n",
    "    for i, C in enumerate(hiddenLayerList):\n",
    "        if TotalEvals.index(min(TotalEvals)) == counter:\n",
    "            BestCs = C\n",
    "            BestQ = Q\n",
    "            print(\"|||THIS ONE BELOW:|||\")\n",
    "        print(\"Q = %lf, C = %s , Ecval = %.20e\" % (Q, C, TotalEvals[counter]))\n",
    "        counter += 1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.212439020050681e-07"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, predict the rate by applying the best hidden layer node number and best alpha value.\n",
    "# Make a prediction on the real data of exchange rates.\n",
    "prob = MLPRegressor(hidden_layer_sizes=(BestCs), max_iter=10000,early_stopping=True, alpha=BestQ)\n",
    "m = prob.fit(Xtrain, ytrain)\n",
    "p_test = prob.predict(Xtest)\n",
    "counter = 0\n",
    "E_test = 0\n",
    "TestError= 0\n",
    "for x, y in np.nditer([p_test, ytest.values],[\"refs_ok\"]):\n",
    "    E_test  = float(x) - float(y)\n",
    "    E_test = E_test**2\n",
    "    counter +=1\n",
    "E_test = E_test/counter\n",
    "E_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "deneme = prob.predict(featureframe[featurecolumns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a23883fd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the actual data, and predicted data alltogether.\n",
    "plotframe = featureframe[\"Closing Rate\"]\n",
    "plotframe = plotframe.to_frame()\n",
    "plotframe2 = pd.DataFrame(deneme,columns=[\"Predict\"])\n",
    "plotframe.plot()\n",
    "plotframe2.plot()\n",
    "plotframe2[\"Closing Rate\"] = plotframe.values\n",
    "plotframe2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005285175165195422"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find out the normalized mean square error.\n",
    "E_test/ytest.values.astype(\"float\").std()**2\n",
    "# Equal to normalized mean square error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Bool\n",
       "count   1186\n",
       "unique     2\n",
       "top     True\n",
       "freq     599"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closeT = (plotframe2[\"Closing Rate\"]-plotframe2.shift(1)[\"Closing Rate\"]).dropna().values\n",
    "predictT = (plotframe2[\"Predict\"]-plotframe2.shift(1)[\"Predict\"]).dropna().values\n",
    "closeT[closeT > 0] = 1\n",
    "closeT[closeT < 0] = -1\n",
    "predictT[predictT > 0] = 1\n",
    "predictT[predictT < 0] = -1\n",
    "\n",
    "trendFrame = pd.DataFrame(data = (predictT == closeT), columns = [\"Bool\"])\n",
    "trendFrame.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
